Bootstrap: docker
From: vllm/vllm-openai:latest

%post
    set -eux

    apt-get update
    apt-get install -y --no-install-recommends \
        clang lld llvm \
        build-essential \
        git ca-certificates curl \
        pkg-config cmake ninja-build
    rm -rf /var/lib/apt/lists/*

    # FIPS workaround: opencv-python-headless >=4.13 bundles a FIPS-enabled
    # OpenSSL 1.1.1k from CentOS/RHEL that crashes on FIPS-enabled hosts.
    # Pin to 4.12.0.88 which does not bundle OpenSSL.
    # See: https://github.com/opencv/opencv-python/issues/1184
    pip install opencv-python-headless==4.12.0.88

    # Pick a Python interpreter that actually exists in the base image
    if command -v python >/dev/null 2>&1; then
        PY=python
    elif command -v python3 >/dev/null 2>&1; then
        PY=python3
    elif [ -x /opt/conda/bin/python ]; then
        PY=/opt/conda/bin/python
    else
        echo "No Python interpreter found (python/python3/conda)."; exit 1
    fi

    # Prefer clang for any builds happening inside the container
    echo "export CC=clang"  >> /etc/profile.d/clang.sh
    echo "export CXX=clang++" >> /etc/profile.d/clang.sh

    # Note: Do NOT upgrade transformers - the vllm-openai base image has
    # compatible versions pinned. Upgrading breaks compatibility.
    
    $PY - << 'PY'
import transformers
import vllm
print("Transformers:", transformers.__version__)
print("vLLM:", vllm.__version__)
PY

%environment
    export LD_LIBRARY_PATH=/usr/local/lib:/usr/lib/x86_64-linux-gnu:/usr/lib${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}

%runscript
    mkdir -p /app
    cd /app
    exec /bin/bash -lc "$@"

%startscript
    mkdir -p /app
    cd /app
    exec /bin/bash -lc "$@"