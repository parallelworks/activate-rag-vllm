Bootstrap: docker
From: vllm/vllm-openai:latest

%post
    set -eux

    apt-get update
    apt-get install -y --no-install-recommends \
        clang lld llvm \
        build-essential \
        git ca-certificates curl \
        pkg-config cmake ninja-build
    rm -rf /var/lib/apt/lists/*

    # Pick a Python interpreter that actually exists in the base image
    if command -v python >/dev/null 2>&1; then
        PY=python
    elif command -v python3 >/dev/null 2>&1; then
        PY=python3
    elif [ -x /opt/conda/bin/python ]; then
        PY=/opt/conda/bin/python
    else
        echo "No Python interpreter found (python/python3/conda)."; exit 1
    fi

    # Prefer clang for any builds happening inside the container
    echo "export CC=clang"  >> /etc/profile.d/clang.sh
    echo "export CXX=clang++" >> /etc/profile.d/clang.sh

    # Note: Do NOT upgrade transformers - the vllm-openai base image has
    # compatible versions pinned. Upgrading breaks compatibility.
    
    $PY - << 'PY'
import transformers
import vllm
print("Transformers:", transformers.__version__)
print("vLLM:", vllm.__version__)
PY

%runscript
    mkdir -p /app
    cd /app
    exec /bin/bash -lc "$@"

%startscript
    mkdir -p /app
    cd /app
    exec /bin/bash -lc "$@"